---
---

@Article{gunawardhana2024toward,
  bibtex_show={true},
  title={Toward User-Aware Interactive Virtual Agents: Generative Multi-Modal Agent Behaviors in VR},
  author={Gunawardhana, Bhasura S and Zhang, Yunxiang and Sun, Qi and Deng, Zhigang},
  booktitle={2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
  abstract={In this paper we propose a novel conditional generative adversarial network (cGAN) architecture, called S2M-Net, to holistically synthesize realistic three-party conversational animations based on acoustic speech input together with speaker marking (i.e., the speaking time of each interlocutor). Specifically, based on a pre-collected three-party conversational motion dataset, we design and train the S2M-Net for three-party conversational animation synthesis. In the architecture, a generator contains a LSTM encoder to encode a sequence of acoustic speech features to a latent vector that is further fed into a transform unit to transform the latent vector into a gesture kinematics space. Then, the output of this transform unit is fed into a LSTM decoder to generate corresponding three-party conversational gesture kinematics. Meanwhile, a discriminator is implemented to check whether an input sequence of three-party conversational gesture kinematics is real or fake. To evaluate our method, besides quantitative and qualitative evaluations, we also conducted paired comparison user studies to compare it with the state of the art.},
  pages={1068--1077},
  year={2024},
  doi={10.1109/ISMAR62088.2024.00123},
  url={https://doi.org/10.1109/ISMAR62088.2024.00123},
  organization={IEEE},
  preview={TwardsUserAwareInteractiveAgents.png},
  selected={false}
}
